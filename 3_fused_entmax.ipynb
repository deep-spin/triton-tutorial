{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd2101-29ec-4893-bc8d-03fc2a522def",
   "metadata": {},
   "outputs": [],
   "source": [
    "from setup_triton import setup_triton\n",
    "\n",
    "# TRITON_INTERPRET=1 uses a python interpreter instead of running on the GPU. \n",
    "# This menas that uou can insert Python breakpoints to debug your kernel code! \n",
    "setup_triton(use_interpreter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925a1804",
   "metadata": {},
   "source": [
    "# Triton Puzzle 3: Fused Entmax\n",
    "\n",
    "Welcome to the third Triton puzzle! Now we'll tackle a more complex operation: fused entmax. \n",
    "\n",
    "### What you'll learn:\n",
    "- How entmax can be computed via the bisection algorithm\n",
    "- How it can be parallelized in Triton\n",
    "\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "The $\\alpha$-entmax mapping is given by:\n",
    "$$\n",
    "{\\alpha\\text{-entmax}(x)}_i = [(\\alpha - 1)x_i - \\tau]_+^{\\frac{1}{\\alpha-1}} \n",
    "$$\n",
    "\n",
    "Thus, for one to calculate entmax, one requires to find $\\tau$ that satistfies $\\sum_i [(\\alpha - 1)x_i - \\tau]_+^{\\frac{1}{\\alpha-1}} = 1$, that is, that satisfies that the sum of all entries sums to one.\n",
    "\n",
    "Let us define the function $f(\\tau)$ for which we are trying to find the root for:\n",
    "$$\n",
    "f(\\tau) = \\sum_i [(\\alpha - 1)x_i - \\tau]_+^{\\frac{1}{\\alpha-1}} - 1\n",
    "$$\n",
    "\n",
    "Currently, in the entmax package (`pip install entmax`) the algorithm to calculate this $\\tau$ for an arbitrary $\\alpha$ makes use of the bisection algorithm. A high-level description of the bisection algorithm goes like this:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Input: }& x \\in \\mathbb{R}^n, \\alpha \\in \\mathbb{R}, T \\text{ iterations} \\\\\n",
    "\\text{(1): }& m \\leftarrow \\max(x) \\\\ \n",
    "\\text{(2): }& \\text{Initialize } \\tau_\\text{lo} = m - 1,\\tau_\\text{hi} = m - n^{1-\\alpha}, \\tau = \\frac{\\tau_\\text{lo} + \\tau_\\text{hi}}{2} \\\\\n",
    "\\text{(3): }& \\text{For t in T iterations do:} \\\\\n",
    "&\\quad\\text{Compute } f(\\tau) \\\\\n",
    "&\\quad\\text{If } f(\\tau) > 0: \\tau_\\text{lo} = \\tau \\text{ else } \\tau_\\text{hi} = \\tau \\\\\n",
    "&\\quad\\tau \\leftarrow \\frac{\\tau_\\text{lo} + \\tau_\\text{hi}}{2} \\\\\n",
    "\\text{(4): }& \\text{Store element-wise }  [(\\alpha - 1)x_i - \\tau]_+^{\\frac{1}{\\alpha-1}} \\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e770371-a6e4-4e77-9880-dd01b3947c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install entmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ba750-d404-47f2-b276-ff8539998739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import triton\n",
    "import triton.language as tl\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Set random seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46876d50",
   "metadata": {},
   "source": [
    "### Complete the code below\n",
    "Assume the following:\n",
    "- The input is a matrix $b \\times n$, and we want to perform the entmax transformation along the last dimension. \n",
    "- $n$ is a power of two, so no masking is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd51564",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.jit\n",
    "def _ent_bisect(x_ptr, y_ptr, alpha, n_iter, N: tl.constexpr, TILE: tl.constexpr):\n",
    "    \n",
    "    # get row that this thread block will be responsible for\n",
    "    curr_row = tl.program_id(0)\n",
    "\n",
    "    # move pointers to the start of the input and output tensors\n",
    "    x_ptr += curr_row * N\n",
    "    y_ptr += curr_row * N\n",
    "\n",
    "    # same as torch.arange\n",
    "    offsets = tl.arange(0, TILE)\n",
    "\n",
    "    # YOUR IMPLEMENTATION GOES HERE\n",
    "    # 1) Calculate the maximum row-wise\n",
    "    # 2) Run bisection `n_iter` times to find tau (be careful about possible NaNs!).\n",
    "    # 3) Finally apply the entmax function with tau and store the result.\n",
    "    pass\n",
    "\n",
    "\n",
    "def entmax_triton(x, alpha=1.5, n_iter=50):\n",
    "    rows, cols = x.shape\n",
    "    assert cols.bit_count() == 1, \"We require the number of columns to be a power of 2.\"\n",
    "    TILE = 1024 if cols > 1024 else cols\n",
    "\n",
    "    # launch with as many programs as rows in x\n",
    "    grid = (rows,)\n",
    "\n",
    "    # allocate output tensor\n",
    "    y = torch.empty_like(x)\n",
    "\n",
    "    # launch the kernel\n",
    "    _ent_bisect[grid](x, y, alpha, n_iter, cols, TILE)\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b77083-76b1-491a-91f0-d6f7242daf2e",
   "metadata": {},
   "source": [
    "## Solution üßô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50895c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa13f39-d30e-4fc1-92b9-d82395f54da5",
   "metadata": {},
   "source": [
    "## Testing Correctness\n",
    "\n",
    "Verify our implementation matches PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3488622-fdaf-4435-8a3d-08c52549d06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_correctness(n_rows=100, n_cols=2048, atol=1e-5, rtol=1e-5):\n",
    "    \"\"\"Test if Triton implementation matches PyTorch.\"\"\"\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    b, n = 16, 4096 * 2\n",
    "    alpha = 1.5\n",
    "    n_iter = 50\n",
    "    \n",
    "    x = torch.randn((b, n), device=DEVICE, dtype=torch.float32).contiguous()\n",
    "    \n",
    "    # Compute with PyTorch\n",
    "    expected = entmax_bisect(x, alpha=alpha, n_iter=n_iter)\n",
    "    \n",
    "    # Compute with Triton\n",
    "    actual = entmax_triton(x, alpha=alpha, n_iter=n_iter)\n",
    "    \n",
    "    try:\n",
    "        torch.testing.assert_close(actual, expected, atol=atol, rtol=rtol)\n",
    "        print(f\"‚úÖ Test PASSED! Results match within tolerance.\")\n",
    "        print(f\"   Shape tested: ({n_rows}, {n_cols})\")\n",
    "        print(f\"   Max absolute difference: {(actual - expected).abs().max().item():.2e}\")\n",
    "        return True\n",
    "    except AssertionError as e:\n",
    "        print(f\"‚ùå Test FAILED!\")\n",
    "        print(f\"   Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run tests\n",
    "test_passed = test_correctness()\n",
    "\n",
    "# Display congrats message\n",
    "if test_passed:\n",
    "    print(\"\\nüéâ Congratulations! Your implementation is correct!\")\n",
    "    display(Image(\"figs/success.gif\", width=256, height=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cb08dd-23d0-488d-ac80-1739ce5753ab",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "1. **Bisection Algorithm**: How to implement root-finding algorithms in parallel on GPUs\n",
    "2. **Multi-pass Kernels**: Processing data multiple times to find global statistics\n",
    "3. **Sparse Activations**: Understanding entmax as a sparse alternative to softmax\n",
    "4. **Numerical Stability**: Using `exp2` and `log2` to handle power operations safely\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **Algorithm Parallelization**: Each row's $\\tau$ can be computed independently\n",
    "- **Memory Efficiency**: All bisection iterations stay in fast SRAM!\n",
    "- **Tiling Strategy**: Processing large vectors in `BLOCK_SIZE` chunks\n",
    "- **Sparse Outputs**: Unlike softmax, entmax can produce exact zeros. Can we leverage this?\n",
    "\n",
    "\n",
    "### Performance Tips:\n",
    "\n",
    "- Use enough bisection iterations (20-50) for convergence\n",
    "- Choose `BLOCK_SIZE` based on your typical sequence lengths\n",
    "- Pre-compute multiplications when possible\n",
    "\n",
    "\n",
    "Next puzzle: matmul!\n",
    "\n",
    "<img src=\"figs/sardine-challenge.png\" width=\"512\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4438f97",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Benchmarking (GPU only)\n",
    "\n",
    "Below you can check how well your solution performs against entmax's package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@triton.testing.perf_report(\n",
    "    triton.testing.Benchmark(\n",
    "        x_names=['size'], \n",
    "        x_vals=[4096, 8192, 16384],\n",
    "        line_arg='provider', \n",
    "        line_vals=['triton', 'torch'],  \n",
    "        line_names=['Triton', 'Torch'],\n",
    "        styles=[('blue', '-'), ('green', '--')], \n",
    "        ylabel='Time (ms)', \n",
    "        plot_name='entmax-perf',\n",
    "        args={},\n",
    "    ))\n",
    "\n",
    "\n",
    "def benchmark(size, provider):\n",
    "    alpha = 1.5\n",
    "    n_iter = 20\n",
    "    x = torch.rand((2048, size), device=\"cuda\", dtype=torch.float32)\n",
    "\n",
    "    quantiles = [0.5, 0.2, 0.8]\n",
    "    if provider == 'torch':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: entmax_bisect(x, n_iter=n_iter, dim=1), quantiles=quantiles, warmup=500, rep=1000)\n",
    "    if provider == 'triton':\n",
    "        ms, min_ms, max_ms = triton.testing.do_bench(lambda: entmax_triton(x, alpha=alpha, n_iter=n_iter), quantiles=quantiles, warmup=500, rep=1000)\n",
    "    return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark.run(print_data=True, show_plots=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
